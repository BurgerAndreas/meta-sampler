#!/bin/bash
# '-t 3-0' for three days
#SBATCH --time=3-00:00:00
#SBATCH --gres=gpu:1 # any
# constraint="RTX_A4500|GTX_1080_Ti" 
#SBATCH --nodes=1
#SBATCH --cpus-per-task=16 # number of cores
#SBATCH --ntasks=1
#SBATCH --mem=32G
#SBATCH --job-name=equiformer 
#SBATCH --output=outslurm/slurm-%j.txt 
#SBATCH --error=outslurm/slurm-%j.txt

# specify list via features: --gres=gpu:1 --constraint="RTX_A4500|GTX_1080_Ti"
# # srun --partition gpunodes -c 4 --mem=8G --gres=gpu:1 --constraint="RTX_A4500|GTX_1080_Ti" -t 60 --pty bash --login

# # slurm_report -g
# # Allocated/Idle/Other/Total

# # scontrol show nodes

# # Example usage:
# # srun --partition gpunodes -c 4 --mem=8G --gres=gpu:rtx_a2000:1 -t 60 --pty bash --login

echo `date`: Job $SLURM_JOB_ID is allocated resources.
echo "Inside slurm_launcher.slrm ($0). received arguments: $@"

HOME_DIR=/home/aburger

export SCRIPTDIR=${HOME_DIR}/meta-sampler

echo " "

# source /home/${USER}/.bashrc
# eval "$(conda shell.bash hook)"
# mamba activate deq
source /home/aburger/miniforge3/envs/meta-sampler/bin/activate

module load cuda/12.6 gcc/12.3

which python

wandb offline
export WANDB_ENTITY=andreas-burger

# hand over all arguments to the script
echo " "
echo "Submitting ${SCRIPTDIR}/$@"

# export WANDB_MODE=online
${HOME_DIR}/miniforge3/envs/meta-sampler/bin/python ${SCRIPTDIR}/"$@"