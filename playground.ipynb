{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import functorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: -0.6057816666140736\n"
     ]
    }
   ],
   "source": [
    "# Set size of matrix\n",
    "N = 2000\n",
    "\n",
    "# Create diagonal matrix with random eigenvalues\n",
    "# One negative eigenvalue and the rest positive\n",
    "eigenvalues = np.concatenate([\n",
    "    [-np.random.rand()],           # One random negative eigenvalue\n",
    "    np.random.rand(N-1) + 1       # N-1 random positive eigenvalues (adding 1 ensures positive)\n",
    "])\n",
    "\n",
    "# Create a random orthogonal matrix for similarity transformation\n",
    "Q, _ = np.linalg.qr(np.random.randn(N, N))\n",
    "\n",
    "# Create the matrix A = Q * D * Q^T where D is diagonal matrix of eigenvalues\n",
    "D = np.diag(eigenvalues)\n",
    "A = Q @ D @ Q.T\n",
    "\n",
    "# Verify eigenvalues\n",
    "print(\"Eigenvalues:\", np.min(np.linalg.eigvals(A)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00106947, -0.60578167])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.sparse.linalg.eigs(A, k=2, return_eigenvectors=False, which='SM').real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6058,  1.0011], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(torch.lobpcg(A, k=2, largest=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hessian_eigenthings import hvp_operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([6])\n",
      "Output shape: torch.Size([1])\n",
      "Output values: tensor(-0.0772, grad_fn=<SqueezeBackward0>)\n",
      "Output values: tensor([-0.0772], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Linear(6, 32)\n",
    "        self.layer2 = torch.nn.Linear(32, 16)\n",
    "        self.layer3 = torch.nn.Linear(16, 1)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.tanh(self.layer1(x))\n",
    "        x = self.tanh(self.layer2(x))\n",
    "        x = self.layer3(x)  # No activation on final layer\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MLP()\n",
    "model_fn = torch.func.functionalize(model)\n",
    "\n",
    "\n",
    "test_input = torch.randn(6)\n",
    "print(\"Input shape:\", test_input.shape)\n",
    "\n",
    "# Test the model\n",
    "output = model(test_input)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output values:\", output.squeeze())\n",
    "print(\"Output values:\", model_fn(test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "v has invalid size: should be torch.Size([6]) but got torch.Size([4, 6]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m      2\u001b[0m hvp_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m s: torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mhvp(model_fn, test_input, s)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mhvp_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[80], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      1\u001b[0m v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m hvp_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m s: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhvp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(hvp_fn(v))\n",
      "File \u001b[0;32m~/miniforge3/envs/dem/lib/python3.10/site-packages/torch/autograd/functional.py:1142\u001b[0m, in \u001b[0;36mhvp\u001b[0;34m(func, inputs, v, create_graph, strict)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     _, v \u001b[38;5;241m=\u001b[39m _as_tuple(v, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhvp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1141\u001b[0m     v \u001b[38;5;241m=\u001b[39m _grad_preprocess(v, create_graph\u001b[38;5;241m=\u001b[39mcreate_graph, need_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1142\u001b[0m     \u001b[43m_validate_v\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_inputs_tuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m inputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnelement() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/dem/lib/python3.10/site-packages/torch/autograd/functional.py:120\u001b[0m, in \u001b[0;36m_validate_v\u001b[0;34m(v, other, is_other_tuple)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_other_tuple:\n\u001b[1;32m    119\u001b[0m     prepend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntry \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprepend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mv has invalid size: should be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mel_other\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mel_v\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: v has invalid size: should be torch.Size([6]) but got torch.Size([4, 6])."
     ]
    }
   ],
   "source": [
    "v = torch.randn(6)\n",
    "hvp_fn = lambda s: torch.autograd.functional.hvp(model_fn, test_input, s)\n",
    "print(hvp_fn(v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn(test_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0337,  0.0541, -0.0585, -0.0282,  0.0077,  0.0416]),)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = torch.randn(6).requires_grad_(True)\n",
    "\n",
    "torch.autograd.grad(model_fn(test_input).sum(-1), test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
