# @package _global_

# to execute this experiment run:
# python train.py experiment=example

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters
defaults:
  - override /energy: aldi2d
  # - override /model/net: egnn 
  # - override /model/noise_schedule: geometric

# alanine dipeptide 2d
tags: ["AlDi", "iDEM"]

seed: 12345

logger:
  wandb:
    tags: ${tags}
    group: "aldi2d"


model:
  noise_schedule:
    _target_: dem.models.components.noise_schedules.GeometricNoiseSchedule
    sigma_min: 0.00001
    sigma_max: 1.0

  buffer:
    prioritize: false
    min_sample_length: 16

  partial_prior:
    _target_: dem.energies.base_prior.Prior
    _partial_: true
    dim: 2

  clipper:
    _target_: dem.models.components.clipper.Clipper
    should_clip_scores: True
    should_clip_log_rewards: False
    max_score_norm: 70
    min_log_reward: null

  lambda_weighter:
    _target_: dem.models.components.lambda_weighter.BasicLambdaWeighter
    _partial_: true
    epsilon: 1e-3

  optimizer:
    lr: 5e-4

  net:
    # _target_: dem.models.components.mlp.MyMLP
    # _partial_: true
    # hidden_size: 128
    # hidden_layers: 3
    # emb_size: 128
    # input_dim: ${energy.dimensionality} # 2                                     
    # out_dim: ${energy.dimensionality} # 2
    # time_emb: "sinusoidal"
    input_emb: "periodic_angle" # sinusoidal -> periodic_angle, periodic_learnable
    periodic_output: "atan2" # atan2, tanh

  diffusion_scale: 1.0

  use_vmap: true
  use_richardsons: True

  # num_init_samples: 1024
  # num_estimator_mc_samples: 100
  # num_samples_to_generate_per_epoch: 1024
  # num_samples_to_sample_from_buffer: 512
  # eval_batch_size: 1024

  # memory cost ~ outer batch size * num_estimator_mc_samples
  # outer batch sizes (number of samples)
  num_samples_to_generate_per_epoch: 32
  num_init_samples: 32
  num_samples_to_sample_from_buffer: 32
  nll_batch_size: 16
  # inner batch size (for each sample)
  num_estimator_mc_samples: 4

  # this has to be max 1000 since test_set is 1000
  eval_batch_size: 32
  scheduler: null


energy:
  use_vmap: ${model.use_vmap}
  batch_size: ${model.num_samples_to_sample_from_buffer}

trainer:
  max_epochs: 100

callbacks:
  rich_progress_bar:
    _target_: lightning.pytorch.callbacks.RichProgressBar
    refresh_rate: 10

matmul_precision: medium